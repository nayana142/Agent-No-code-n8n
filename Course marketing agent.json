{
  "name": "Course marketing agent",
  "nodes": [
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.3,
      "position": [
        -416,
        -32
      ],
      "id": "71138412-0d99-4c31-99ff-66c2ae007510",
      "name": "When chat message received",
      "webhookId": "48ec83df-a41c-4c0c-aa55-b6953746038d"
    },
    {
      "parameters": {
        "options": {
          "systemMessage": "=# Overview  \nYou are an AI assistant that answers user questions about the trainer’s courses using the Pinecone vector database. You provide accurate, concise, and helpful answers only from the stored course content. If the user greets you, you respond with a short, polite welcome before waiting for their course-related question.\n\n## Context  \n- All course information comes from a Pinecone vector store populated with embeddings from the trainer’s own course materials.  \n- Google Gemini is used for embeddings and chat generation.  \n- The assistant must not invent information not in the vector database.  \n- Greeting messages (e.g., \"hi\", \"hello\", \"hai\", \"hey\") should receive a friendly acknowledgment even if unrelated to course content.  \n\n## Instructions  \n1. When the user sends a greeting (e.g., \"hi\", \"hello\", \"hai\", \"hey\"):  \n   - Respond briefly and warmly, such as: \"Hello! How can I help you with our courses today?\"  \n   - Do not query Pinecone for greetings.  \n2. When the user asks a course-related question:  \n   - Generate query embeddings using Google Gemini.  \n   - Search Pinecone vector store for matches.  \n   - Retrieve and summarize relevant course details from the results.  \n3. If no relevant match is found:  \n   - Politely inform the user no course information is available for that topic.  \n4. If an error occurs (e.g., vector store or embedding failure):  \n   - Respond with a friendly fallback message like:  \n     *\"I’m having trouble accessing the course database right now. Could we try again in a moment?\"*  \n5. Always keep responses clear, concise, and aligned to the retrieved course content.\n\n## Tools  \n- **Google Gemini Chat Model**: Generates conversational responses.  \n- **Google Gemini Embeddings**: Converts queries into vector representations for searching.  \n- **Pinecone Vector Store**: Stores and retrieves embeddings for course content.  \n- **Answer Questions with a Vector Store**: Handles retrieval-based Q&A.  \n- **Simple Memory**: Tracks conversational context within the session.  \n\n## Examples  \n- **Greeting Input:** \"hai\"  \n  - Output: \"Hello! How can I help you with our courses today?\"  \n\n- **Course Question Input:** \"What topics are in your Data Science course?\"  \n  - Process: Embed → Search Pinecone → Retrieve → Summarize.  \n  - Output: \"Our Data Science course covers Python programming, data wrangling, exploratory analysis, machine learning algorithms, and model evaluation.\"  \n\n- **No Match Found Input:** \"Do you teach swimming?\"  \n  - Output: \"I don’t have any information about a swimming course in my records. Could you ask about one of our listed courses?\"  \n\n## SOP (Standard Operating Procedure)  \n1. Identify if the input is a greeting or course-related question.  \n2. If greeting → send short welcome and wait for a question.  \n3. If question → generate embeddings and search Pinecone.  \n4. Summarize and respond using only retrieved course content.  \n5. Use polite fallback messages if there’s no match or an error occurs.\n\n## Final Notes  \n- Always greet when the user greets, even without course data.  \n- Never fabricate course information.  \n- Keep tone professional yet friendly.\n"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        -128,
        -32
      ],
      "id": "1dfc5c9d-bdfe-42b8-b74b-f3ebdd7ba187",
      "name": "AI Agent"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        -304,
        176
      ],
      "id": "52d72f3b-8a86-40c5-96f9-d2c47c13cfdf",
      "name": "Google Gemini Chat Model",
      "credentials": {
        "googlePalmApi": {
          "id": "5A0mdluJGCEyufEi",
          "name": "Google Gemini(PaLM) Api account 2"
        }
      }
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        -112,
        192
      ],
      "id": "d904d7f3-6def-405d-84c2-e34f902f0738",
      "name": "Simple Memory"
    },
    {
      "parameters": {
        "description": "Use this tool to get any information asked by the user."
      },
      "type": "@n8n/n8n-nodes-langchain.toolVectorStore",
      "typeVersion": 1.1,
      "position": [
        272,
        160
      ],
      "id": "b3cd49f1-b36c-42b6-a824-7acb96101a9f",
      "name": "Answer questions with a vector store"
    },
    {
      "parameters": {
        "pineconeIndex": {
          "__rl": true,
          "value": "galtech-syllabus",
          "mode": "list",
          "cachedResultName": "galtech-syllabus"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "typeVersion": 1.3,
      "position": [
        128,
        352
      ],
      "id": "28f79ed2-b73e-4073-9664-1cc75b09ff90",
      "name": "Pinecone Vector Store",
      "credentials": {
        "pineconeApi": {
          "id": "V5P0xr0BxgNqUV2w",
          "name": "PineconeApi account 3"
        }
      }
    },
    {
      "parameters": {
        "modelName": "models/embedding-001"
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsGoogleGemini",
      "typeVersion": 1,
      "position": [
        192,
        512
      ],
      "id": "740a85cc-8cc1-49fa-b227-acad4c39fa5e",
      "name": "Embeddings Google Gemini",
      "credentials": {
        "googlePalmApi": {
          "id": "5A0mdluJGCEyufEi",
          "name": "Google Gemini(PaLM) Api account 2"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        480,
        336
      ],
      "id": "6283cd95-be9b-43e2-95a9-9b160c674cfa",
      "name": "Google Gemini Chat Model1",
      "credentials": {
        "googlePalmApi": {
          "id": "5A0mdluJGCEyufEi",
          "name": "Google Gemini(PaLM) Api account 2"
        }
      }
    },
    {
      "parameters": {
        "documentId": {
          "__rl": true,
          "value": "1VymEhhBVlTuvn3E3CasjNYHsuBRJacCuvsUv4axxov0",
          "mode": "list",
          "cachedResultName": "Galtech fee structure",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1VymEhhBVlTuvn3E3CasjNYHsuBRJacCuvsUv4axxov0/edit?usp=drivesdk"
        },
        "sheetName": {
          "__rl": true,
          "value": "gid=0",
          "mode": "list",
          "cachedResultName": "Sheet1",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1VymEhhBVlTuvn3E3CasjNYHsuBRJacCuvsUv4axxov0/edit#gid=0"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleSheetsTool",
      "typeVersion": 4.6,
      "position": [
        64,
        192
      ],
      "id": "99d27310-975a-4169-a4ca-33eeb411c8b7",
      "name": "Fee Structure",
      "credentials": {
        "googleSheetsOAuth2Api": {
          "id": "XHbg3YuiiIiwh8JA",
          "name": "Nayana_galtech"
        }
      }
    }
  ],
  "pinData": {},
  "connections": {
    "When chat message received": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Simple Memory": {
      "ai_memory": [
        [
          {
            "node": "AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Answer questions with a vector store": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Pinecone Vector Store": {
      "ai_vectorStore": [
        [
          {
            "node": "Answer questions with a vector store",
            "type": "ai_vectorStore",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings Google Gemini": {
      "ai_embedding": [
        [
          {
            "node": "Pinecone Vector Store",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Answer questions with a vector store",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Fee Structure": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "2c5ab172-d438-4382-8954-73495fc027c3",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "6ae6435382c4da0f9a88fd7eff013c6028337c2272750b4c951c6df4243367ad"
  },
  "id": "NZJR19YOJgaGluNF",
  "tags": []
}